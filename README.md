Linear phase parser
Pauli Brattico
2020

The linear phase parser analyses language by simulating human language comprehension. The program was originally created at IUSS, Pavia, in a research project "ProGraM-PC: A Processing-friendly Grammatical Model for Parsing and predicting on-line Complexity". Documentation is in the /docs folder, and research paper preprints are in /docs/Article preprints and supplementary documents. The system is a tool for linguistics and language comprehension research in that it allows one to model the comprehension of language (semantic interpretation, grammaticality judgments, etc.) at any level of detail desired and under completely formal and rigorous regimen.

The program reads sentences (linear sequences of unannotated words in any language) as input and figures out their meaning by applying a series of language comprehension principles of the human brain. If the input is judged ungrammatical, semantic interpretation is not generated and the input is judged ungrammatical. The model provides also a large collection of quantitative data, such as number and timing (ms from stimulus onset) of all of its internation operations, which can be used to assess cognitive load and perceived "unnaturalness" of the input sentence. I am working on system that allows one to map this data further to brain localization. 

To run the program, you must have python installed and configured at your local machine. After cloning the repository, type 'python lpparse' into command prompt inside the main folder where the package is installed. This command should process all sentences from a test corpus file (that is, if the latest version you have cloned is functional, usually it is). You should see the output in the console. To generate phrase structure images, you need the pyglet package at the local machine. To install it, write 'pip install pyglet' in the command prompt or see the pyglet installation instructions. 

The test corpus file, which contains all the sentences processed by the algorithm, is provided inside /language data working directory/xxx, where 'xxx' refers to an individual study folder. This is done so as to preserve a copy of the data used in each published/submitted study, and to make it possible to work with several studies at the same time. The output will be generated to the same directory. All this information is provided in the config.txt file that is in the main directory. Thus, if config.txt contains lines "test_corpus_file:	linear_phase_theory_corpus.txt" and 
"study_folder: study-6-linear-phase-theory", then the former will contain the sentences that are processed and the latter its folder; all output will appear inside the same folder. At present, the lexicon (which is also provided as external files) is provided in the /language data working directory and is therefore the same for each study, as I am currently working with a cumulative model that is not allowed to break previous results. These files should be copied however to the study subfolder in connection with each study to preserve a snapshot of the lexicon and for replication purposes. Each word in the test corpus file should appear in the lexicon.

The output is generated into the study folder defined in 'config.txt' hosting the test corpus as well. The following outputs are generated: a list of input sentences and whether the model judged then grammatical or ungrammatical (...grammaticality_judgments.txt); more detailed phrase structure analyses and semantic interpretation (...results.txt); a detailed csv data concerning the number of operations (...resources.txt) that can be processed easily for example with Python pandas and matplotlib; a detailed log of virtually every operation that occurred during the processing (...log.txt); a detailed list of the order of all operations and their timings (ms)(...resource_sequence). Phrase structure images are generated inside /phrase structure images if the study is configured to make them. In a real empirical study the focus is alwyas first on observational adequacy, i.e. whether the algorithm replicates human behavior. Once the model reaches that criterion, we look at the rest of the output and make necessary adjustments without breaking observational adequacy.

Should the user want to examine the derivation of only one sentence,  that sentence can be prefaced with symbol % in the test corpus file. Then only that sentence will be processed. If the user wants to process a batch of sentences, they can be selected by writing =START= and =STOP= at the beginning of the respective starting and stopping lines, and the algorithm will process every sentence between.

The system is used in a typical study in the following way. The linguistic phenomenon that will be focus of the study is first operationalized by means of test sentences. Thus, we select what type of linguistic examples (sentences, meanings) will best exemplify the phenomenon we are interested. These are collected into the test corpus and organized in some systematic way. Say we are interested in the processing of noncanonical word order in French causative constructions. The test corpus is in this case created by generating most or all possible word order combinations from basic causative sentences in French. These are further classified as grammatical or ungrammatical, so that we have a "gold standard" (human behavior) against which we measure the performance of the model. A hypothesis is then developed concerning the principles regulating word order in French causatives. The hypothesis could involve phonological, morphological, syntactic, semantic or discourse features. The candidate hypotheses are formalized in terms of cognitive principles of language comprehension, i.e. how a native speaker would process them in real time, after which we determine by running the comprehension algorithm if they are sufficient to derive the attested properties of the test sentences (grammaticality, plausibility, meaning). If they are, we gain confidence on the hypothesis. If they are not, comparison between the model output and the gold standard reveal what its weaknesses are, guiding further theorizing. An important feature of this methdology is that it does not rely on human intuition, guesswork or natural language syllogisms; there is no point in the derivation at which the user can intervene. Another positive feature is that verification is fast: the model consumes less than 100ms while processing each sentence (more realistic brain chronology is provided externally), so that we could easily use it to process millions of test sentences.
