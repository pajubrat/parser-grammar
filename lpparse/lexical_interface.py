import phrase_structure
from collections import defaultdict
from lexical_item import LexicalItem
from support import log, log_instance

MBOUNDARY = ('#', '_', '=')


# Definition for lexical interface
class LexicalInterface:
    def __init__(self, speaker_model):
        self.speaker_model = speaker_model
        self.PhraseStructure = phrase_structure.PhraseStructure
        self.speaker_lexicon = defaultdict(list)
        self.redundancy_rules = self.load_redundancy_rules()
        self.language = self.speaker_model.language

    def lexical_retrieval(self, phon):
        log(f'\n\tNext morpheme /{phon}/ retrieves ')
        phon, onset, offset = self.phonological_context(phon)
        if phon in self.speaker_lexicon:
            lexical_items_lst = [lex.copy().set_phonological_context(onset, offset) for lex in self.speaker_lexicon[phon] if
                                 self.language_match(lex) and self.phonological_context_match(lex, onset, offset)]
        else:
            lexical_items_lst = [self.unknown_word(phon)]
        self.log_lexical_items(phon, lexical_items_lst)
        self.speaker_model.results.consume_resources('Lexical Retrieval', phon)
        return lexical_items_lst

    def phonological_context(self, phon):
        onset = ''
        offset = ''
        # Independent word
        if not phon.startswith(MBOUNDARY) and not phon.endswith(MBOUNDARY):
            return phon, '_', '_'
        # Get onset
        if phon.startswith(MBOUNDARY):
            onset = phon[0]
        # Get offset
        if phon.endswith(MBOUNDARY):
            offset = phon[-1]
        return phon[len(onset):len(phon)-len(offset)], onset, offset

    def log_lexical_items(self, phon, lst):
        log(f' ')
        for i, lex in enumerate(lst):
            if lex:
                if lex.morphological_chunk:
                    log(f'({i+1}) morphological chunk [{lex.morphological_chunk}] ')
                else:
                    log(f'({i+1}) {lex} ')

    def phonological_context_match(self, lex, onset, offset):
        for phon_context in [f.split(':')[1] for f in lex.features if f.startswith('PC')]:
            if (phon_context[0] != 'X' and phon_context[0] != onset) or (phon_context[-1] != 'X' and phon_context[-1] != offset):
                return False
        return True

    def unknown_word(self, w):
        lex = LexicalItem()
        lex.features = {f'PF:{w}', '?'}
        lex.name = '?'
        if '#' in w:
            lex.morphological_chunk = w
            lex.internal = True
        elif '=' in w:
            lex.morphological_chunk = w
            lex.internal = True
        else:
            log(f' = Unrecognized word')
            print(f'Word {w} was not recognized.')
            self.speaker_model.exit = True
        return lex

    def language_match(self, lex):
        return (self.language in lex.language) or (lex.language == 'LANG:X')

    def apply_redundancy_rules(self, current_feature_lst):
        """Applies features by lexical redundancy rules (LRRs) until the set of lexical features stabilizes (no longer changes)
        This version allows execution of LRRs in a sequence
        Structure of the algorithm: WHILE (LRRs would add new features F) ADD F
        Return the new feature set after combining and pruning
        """
        # Add features until there are no more new features. This allows iterative application, so that features
        # introduced by lexical redundancy rules can trigger further rules.
        new_feature_lst = []
        for fset in current_feature_lst:
            fset = self.lexical_redundancy(fset)
            new_feature_lst.append(fset)
        return new_feature_lst

    def lexical_redundancy(self, fset):
        def opposite_feature(feature):
            """Defines the notion of opposite feature"""
            if feature.startswith('-'):
                return feature[1:]
            return '-' + feature

        def default_rule(feature, current_features):
            """Lexical redundancy rule applies if and only if
            (1) the feature does not exist in the lexical item already
            (2) the opposite feature does not block the application (default principle)'
            """
            return feature not in current_features and opposite_feature(feature) not in current_features

        def rule_trigger(f, features):
            """Lexical redundancy rule applies if the triggering features all exist in the lexical entry"""
            return set(f.split()) <= features

        def new_features(fset):
            """New features are generated by triggered lexical redundancy rules minus features that
            are blocked by the default principle (lexical features override lexical redundancy features)
            """
            new = set()
            for rule in [rule for rule in self.redundancy_rules.keys() if rule_trigger(rule, fset)]:
                new = new | {feature for feature in self.redundancy_rules[rule] if default_rule(feature, fset)}
            return new

        while new_features(fset):
            fset = fset | new_features(fset)
        return self.combine_features(fset)

    def combine_features(self, features):
        """Maps [X:Y] + [X:Z] into [X:Y,Z]"""
        feature_dict = {}
        unmodified_features = features.copy()
        for feature in features:
            if len(feature.split(':')) == 2:
                if 'SPEC' in feature or 'COMP' in feature or 'SELF' in feature:
                    key, value = feature.split(':')
                    if key in feature_dict.keys():
                        feature_dict[key] |= set(value.split(','))
                    else:
                        feature_dict[key] = set(value.split(','))
                    unmodified_features.discard(feature)
        new_aggregrated_features = {f'{key}:{",".join(feature_dict[key])}' for key in feature_dict.keys()}
        return unmodified_features | new_aggregrated_features

    def load_redundancy_rules(self):
        redundancy_rules_dict = {}
        for line in open(self.speaker_model.settings.external_sources["redundancy_rules"], encoding='utf8'):    #todo remove SM from settings access
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            antecedent, features = line.split('::', 1)
            antecedent = antecedent.strip()
            feature_set = {f.strip() for f in features.split()}
            if antecedent in redundancy_rules_dict.keys():
                redundancy_rules_dict[antecedent] = redundancy_rules_dict[antecedent] | feature_set
            else:
                redundancy_rules_dict[antecedent] = feature_set
        return redundancy_rules_dict

    def load_lexicons(self, settings):
        self.speaker_lexicon = {}
        for lexicon_file in [file.strip() for file in settings.retrieve('file_lexicons', '').split(';')]:
            self.load_and_create_lexicon(settings.folders['lexicon'] / lexicon_file)

    def load_and_create_lexicon(self, lexicon_file):
        lexical_entries = []
        if lexicon_file:
            lexical_entries = open(lexicon_file, encoding='utf8').readlines()

        for line in lexical_entries:
            if not line or '::' not in line or line.startswith('#'):
                continue
            line = line.strip()
            phonological_entries, lexical_features = line.split('::')
            phonological_entries = phonological_entries.strip().split(',')
            lexical_feature_set = {f.strip() for f in lexical_features.split()}
            if not {f for f in lexical_feature_set if f[:4] == 'LANG'}:
                lexical_feature_set.add(self.language)
            for p in phonological_entries:
                lex = LexicalItem(name=p, features=self.lexical_redundancy(lexical_feature_set))
                if p not in self.speaker_lexicon.keys():
                    self.speaker_lexicon[p] = []
                self.speaker_lexicon[p].append(lex)
